{"cells":[{"cell_type":"code","execution_count":null,"id":"5bda3ec3-3d8d-40f1-974e-9cdb6d541fd4","metadata":{"id":"5bda3ec3-3d8d-40f1-974e-9cdb6d541fd4"},"outputs":[],"source":["# KNN\n","\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import KFold\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# 데이터 로드\n","data = pd.read_excel(r\"C:\\Users\\user\\Desktop\\팀프로젝트\\mlb_dp_20.xlsx\")\n","X = data.drop(columns=[\"theta_p\", \"theta_n\", \"distance\"])\n","y = data[[\"theta_p\", \"distance\"]]\n","\n","# 1차: Train(80%) + Test(20%) 분할\n","from sklearn.model_selection import train_test_split\n","X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 2차: Train(60%) + Validation(20%) 분할 (Train+Validation을 다시 나눔)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n","\n","# KNN 모델 정의\n","knn = KNeighborsRegressor(n_neighbors=10)\n","\n","# 다중출력 회귀 모델 정의\n","multi_target_knn = MultiOutputRegressor(knn)\n","\n","# KFold 교차 검증 설정\n","kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n","\n","# 평가 지표 계산 함수 정의\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))\n","\n","def mse(y_true, y_pred):\n","    return mean_squared_error(y_true, y_pred)\n","\n","def mae(y_true, y_pred):\n","    return mean_absolute_error(y_true, y_pred)\n","\n","def mape(y_true, y_pred):\n","    # MAPE 계산 시 0 값에 대해 오류를 방지하기 위해 작은 값으로 나누기\n","    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100  # 백분율로 변환\n","\n","# X_train과 y_train을 리셋한 후 KFold 적용\n","X_train = X_train.reset_index(drop=True)\n","y_train = y_train.reset_index(drop=True)\n","\n","# 교차 검증 후 MSE, MAE, RMSE, MAPE 출력\n","fold = 1\n","for train_index, val_index in kfold.split(X_train):\n","    X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n","    y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n","\n","    # 모델 훈련\n","    multi_target_knn.fit(X_train_fold, y_train_fold)\n","\n","    # 예측\n","    y_pred = multi_target_knn.predict(X_val_fold)\n","\n","    # MSE, MAE, RMSE, MAPE 계산 (두 출력값에 대해서 동시에 계산)\n","    fold_mse = mse(y_val_fold, y_pred)\n","    fold_mae = mae(y_val_fold, y_pred)\n","    fold_rmse = rmse(y_val_fold, y_pred)\n","    fold_mape = mape(y_val_fold, y_pred)\n","\n","    # 각 fold별 결과 출력\n","    print(f\"Fold {fold}:\")\n","    print(f\"  MSE: {fold_mse:.4f}\")\n","    print(f\"  MAE: {fold_mae:.4f}\")\n","    print(f\"  RMSE: {fold_rmse:.4f}\")\n","    print(f\"  MAPE: {fold_mape:.4f}%\\n\")\n","\n","    fold += 1\n"]},{"cell_type":"code","execution_count":null,"id":"5aca3794-6e4d-42b7-bc41-d1c339927c2e","metadata":{"id":"5aca3794-6e4d-42b7-bc41-d1c339927c2e"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e1e1c616-35d5-4f2f-a9ce-2b818dbcf135","metadata":{"id":"e1e1c616-35d5-4f2f-a9ce-2b818dbcf135"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"e29ad5b6-b52a-4c35-9521-4ec88b2f0b60","metadata":{"id":"e29ad5b6-b52a-4c35-9521-4ec88b2f0b60"},"outputs":[],"source":["# optuna\n","\n","!pip install optuna\n","import optuna\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import KFold\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","# 데이터 로드\n","data = pd.read_excel(r\"C:\\Users\\user\\Desktop\\팀프로젝트\\mlb_dp_20.xlsx\")\n","X = data.drop(columns=[\"theta_p\", \"theta_n\", \"distance\"])\n","y = data[[\"theta_p\", \"distance\"]]\n","\n","# 1차: Train(80%) + Test(20%) 분할\n","from sklearn.model_selection import train_test_split\n","X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n","\n","# 2차: Train(60%) + Validation(20%) 분할 (Train+Validation을 다시 나눔)\n","X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=1234)\n","\n","# KFold 교차 검증 설정\n","kfold = KFold(n_splits=5, shuffle=True, random_state=1234)\n","\n","# 평가 지표 계산 함수 정의\n","def rmse(y_true, y_pred):\n","    return np.sqrt(mean_squared_error(y_true, y_pred))\n","\n","def mape(y_true, y_pred):\n","    return np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100  # 백분율로 변환\n","\n","# Optuna 목적 함수 정의\n","def objective(trial):\n","    # 하이퍼파라미터 정의\n","    n_neighbors = trial.suggest_int('n_neighbors', 8, 22)\n","    weights = trial.suggest_categorical('weights', ['uniform', 'distance'])\n","    algorithm = trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute'])\n","    leaf_size = trial.suggest_int('leaf_size', 10, 50)\n","    p = trial.suggest_int('p', 1, 2)\n","    metric = trial.suggest_categorical('metric', ['minkowski', 'euclidean', 'manhattan', 'chebyshev'])\n","\n","    # KNN 모델 정의\n","    knn = KNeighborsRegressor(n_neighbors=n_neighbors, weights=weights, algorithm=algorithm,\n","                              leaf_size=leaf_size, p=p, metric=metric)\n","    multi_target_knn = MultiOutputRegressor(knn)\n","\n","    # 교차 검증 후 MSE, MAE, RMSE, MAPE 계산\n","    fold_rmse_list = []\n","    fold_mape_list = []\n","\n","    for train_index, val_index in kfold.split(X_train):\n","        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n","        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n","\n","        # 모델 훈련\n","        multi_target_knn.fit(X_train_fold, y_train_fold)\n","\n","        # 예측\n","        y_pred = multi_target_knn.predict(X_val_fold)\n","\n","        # RMSE와 MAPE 계산\n","        fold_rmse_list.append(rmse(y_val_fold, y_pred))\n","        fold_mape_list.append(mape(y_val_fold, y_pred))\n","\n","    # RMSE와 MAPE의 평균을 구함\n","    avg_rmse = np.mean(fold_rmse_list)\n","    avg_mape = np.mean(fold_mape_list)\n","\n","    # 가중합\n","    return 0.7 * avg_rmse + 0.3 * (avg_mape / 100)  # 가중합 (MAPE를 %에서 소수로 변환)  # RMSE 최적화\n","\n","# Optuna의 최적화 실행\n","study = optuna.create_study(direction='minimize')  # 최소화 목표\n","study.optimize(objective, n_trials=50)\n","\n","# 최적의 하이퍼파라미터 확인\n","print(f\"Best trial: {study.best_trial.params}\")\n"]},{"cell_type":"code","execution_count":null,"id":"de70fee4-5413-4332-b3cd-d5ccb6ef55f5","metadata":{"id":"de70fee4-5413-4332-b3cd-d5ccb6ef55f5"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"69e69c1a-5509-4ccc-ba97-e7a00ded56e6","metadata":{"id":"69e69c1a-5509-4ccc-ba97-e7a00ded56e6"},"outputs":[],"source":["# 최적 모델 저장\n","\n","import pickle\n","\n","opt_knn = KNeighborsRegressor(**study.best_params)\n","file_name = \"KNN_model.pkl\"\n","with open(file_name, \"wb\") as f:\n","    pickle.dump(opt_knn, f)\n","print(f\"✅ 모델이 {file_name}에 저장되었습니다.\")"]},{"cell_type":"code","execution_count":null,"id":"56c70a43-2c8d-4025-86e2-fb51dc73a7bc","metadata":{"id":"56c70a43-2c8d-4025-86e2-fb51dc73a7bc"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ba53e576-3380-4fd6-a655-596b0f405935","metadata":{"id":"ba53e576-3380-4fd6-a655-596b0f405935"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"be8e6c00-cc9a-4784-9d40-2095cea1a2f4","metadata":{"id":"be8e6c00-cc9a-4784-9d40-2095cea1a2f4"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}